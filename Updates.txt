October 2nd: Downloaded my reads from the google drive and prepared for QA/QC. Code is shown below. 

gdown.pl  https://drive.google.com/1dJHIeN-7pY9nDAz3Ia8QObJvTjbj-9HY/edit GAB_R1.fastq.gz

gdown.pl https://drive.google.com/1n_rpyjTiZjdKW4ICZDYYpf-osMIqAi71/edit GAB_R2.fastq.gz


October 3rd: Did quality assesment on both scratch drive and personal directory. Also transfered files from Colossus onto desktop to continue foreward. R1 quality assesment was good however R2 was of much less quality. 

Code used: fastqc GAB_R1.fastq.gz and fastqc GAB_R2.fastq.gz
Overall reads were decent but some quality control needed to be done to improve results. 


October 12th: Used cutadapt to get rid of primers on both R1 and R2. Following this ran spades and quast to make the assembly. R1 was trimmed 26522 times while R2 was trimmed 29816 times. After running spades it was completed with an errror correction and assembly warning. 

Code used: cutadapt -q 20,20 -a CTGTCTCTTATACACATCTCCGAGCCCACGAGAC -A CTGTCTCTTATACACATCTGACGCTGCCGACGA -m 50 --max-n 0 -o GAB_R1.cutadapt.fastq -p GAB_R2.cutadapt.fastq GAB_R1.fastq.gz GAB_R2.fastq.gz

For Spades: spades.py -k 21,51,71,91,111,127 --careful --pe1-1 GAB_R1.cutadapt.fastq --pe1-2 GAB_R2.cutadapt.fastq -o GAB_spades_output

For Quast: quast contigs.fasta -o Quast_contigs

Following this code WinSCP was used to trasfer the report.html file onto the computer. 
After Quast documents were moved over, the .html files were looked at in order to determine if the Spades assembly was of good quality. 
After looking at the Quast .html it was found to be of good quality due to its N50, overall length and number of contigs and the E value. 


Following Quast contig generation prokka was used. 

October 29th
Prokka code: awk '/^>/{print ">T1_" ++i; next}{print}' < contigs.fasta > contigs_names.fasta
This line allowed us to run prokka with our contig files by modifying the names to be shorter. 
Next line: prokka --outdir GAB --prefix GAB contigs_names.fasta
This line ran annotation on our GAB contigs fasta file. 

Following this many files were generated for analysis. This allowed us to analize the congits and gene data that came from annotation. These are such things as COD and EC numbers. This allowed us to see what proteins and genes are in the organism. From here we could finally begin to generate our resource announcment paper/document. 
The overall number of COGs that were in the assembly were: 1618
In addition following annotation we then were able to see how many genes there were as well as non-coding regions there were. 
Number of genes: 2107
Code for gene collection:
cut -f4 GAB.tsv > genes.txt *this line of code cut column 4 (the one with gene names in it) and put it into a text file)
sed -i '/^$/d' genes.txt *this line got rid of all empty rows within genes.txt as those without gene names are potential proteins but are not confirmed. 
wc -l genes.txt *this line of code counted the number of lines in genes.txt so we knew how many actualy genes there were in the counstruct. 
